{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "794c7bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sys, os\n",
    "\n",
    "import importlib, time\n",
    "import traceback\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from torch.utils.data import DataLoader\n",
    "from humor.body_model.body_model import BodyModel\n",
    "\n",
    "from humor.utils.config_new import ConfigParser\n",
    "from humor.utils.logging import Logger, class_name_to_file_name, mkdir, cp_files\n",
    "from humor.utils.torch import get_device, save_state, load_state\n",
    "from humor.utils.stats import StatTracker\n",
    "from humor.models.model_utils import step\n",
    "\n",
    "import smplx\n",
    "import torch\n",
    "from smplx import SMPL, SMPLH, SMPLX\n",
    "\n",
    "import pickle\n",
    "\n",
    "NUM_WORKERS = 4\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58f2fe50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default: {'ckpt', 'load_optim', 'decay', 'beta2', 'eps', 'use_adam', 'beta1'}\n",
      "Using default: {'detach_sched_samp', 'output_delta', 'model_use_smpl_joint_inputs'}\n",
      "Using default: {'frames_out_step_size', 'data_noise_std', 'splits_path'}\n",
      "Using default: set()\n",
      "base_dict: {'dataset': 'AmassDiscreteDataset', 'model': 'HumorDiffusionTransformer', 'loss': 'DiffusionLoss', 'out': './out/humordiffusiontransformer_train', 'ckpt': None, 'gpu': 0, 'batch_size': 64, 'print_every': 10, 'epochs': 200, 'val_every': 2, 'save_every': 25, 'lr': 0.0001, 'beta1': 0.9, 'beta2': 0.999, 'eps': 1e-08, 'sched_milestones': [20, 40, 80], 'sched_decay': 0.5, 'decay': 0.0, 'load_optim': True, 'use_adam': False, 'sched_samp_start': -1, 'sched_samp_end': -2}\n",
      "model_dict: {'out_rot_rep': 'aa', 'in_rot_rep': 'mat', 'latent_size': 128, 'steps_in': 1, 'output_delta': True, 'model_data_config': 'smpl+joints+contacts', 'detach_sched_samp': True, 'model_use_smpl_joint_inputs': False, 'pose_token_dim': 64, 'diffusion_base_dim': 256, 'nhead': 4, 'num_layers': 6, 'dim_feedforward': 1024, 'dropout': 0.1, 'cfg_scale': 4.0, 'cond_drop_prob': 0.1, 'use_mean_sample': True}\n",
      "dataset_dict: {'data_paths': ['../datasets/AMASS/amass_processed'], 'split_by': 'sequence', 'splits_path': None, 'sample_num_frames': 10, 'data_rot_rep': 'mat', 'step_frames_in': 1, 'step_frames_out': 1, 'frames_out_step_size': 1, 'data_return_config': 'smpl+joints+contacts', 'data_noise_std': 0.0}\n",
      "loss_dict: {'ddpm': 1.0}\n"
     ]
    }
   ],
   "source": [
    "config_path = r\"configs\\train_diffusion_transformer.yaml\"\n",
    "config_parser_yaml = ConfigParser(config_path)\n",
    "args_obj, _ = config_parser_yaml.parse('train')\n",
    "# See config\n",
    "dict_attr = ['base_dict', 'model_dict', 'dataset_dict', 'loss_dict']\n",
    "for attr in dict_attr:\n",
    "    print(f\"{attr}: {getattr(args_obj, attr)}\")\n",
    "args = args_obj.base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c49071f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: {'out_rot_rep': 'aa', 'in_rot_rep': 'mat', 'latent_size': 128, 'steps_in': 1, 'output_delta': True, 'model_data_config': 'smpl+joints+contacts', 'detach_sched_samp': True, 'model_use_smpl_joint_inputs': False, 'pose_token_dim': 64, 'diffusion_base_dim': 256, 'nhead': 4, 'num_layers': 6, 'dim_feedforward': 1024, 'dropout': 0.1, 'cfg_scale': 4.0, 'cond_drop_prob': 0.1, 'use_mean_sample': True}\n",
      "Using default: {'ckpt', 'load_optim', 'decay', 'beta2', 'eps', 'use_adam', 'beta1'}\n",
      "Using default: {'output_delta', 'model_use_smpl_joint_inputs', 'detach_sched_samp'}\n",
      "Using default: {'frames_out_step_size', 'data_noise_std', 'splits_path'}\n",
      "Using default: {'kl_loss_cycle_len', 'smpl_vert_consistency_loss'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\workspace\\Motion\\humor\\humor\\utils\\torch.py:47: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  full_checkpoint_dict = torch.load(load_path, map_location=map_location)\n"
     ]
    }
   ],
   "source": [
    "from humor.models.humor_diffusion_transformer import HumorDiffusionTransformer\n",
    "print(f\"Model: {args_obj.model_dict}\")\n",
    "model = HumorDiffusionTransformer(**args_obj.model_dict,\n",
    "                                  vae_ckpt=r'out\\motion_vae\\20250506_014121\\checkpoints\\best_model.pth',\n",
    "                                  vae_cfg=r'configs\\train_motion_vae.yaml',\n",
    "                                  model_smpl_batch_size=args.batch_size,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e092b369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using detected GPU...\n"
     ]
    }
   ],
   "source": [
    "device = get_device(args.gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "466bd46d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from../datasets/AMASS/amass_processed\n",
      "Logger must be initialized before logging!\n",
      "This split contains 2425 sequences (that meet the duration criteria).\n",
      "Logger must be initialized before logging!\n",
      "The dataset contains 106399 sub-sequences in total.\n",
      "Logger must be initialized before logging!\n"
     ]
    }
   ],
   "source": [
    "from humor.datasets. amass_discrete_dataset import AmassDiscreteDataset\n",
    "\n",
    "train_dataset = AmassDiscreteDataset(split='train', **args_obj.dataset_dict,)\n",
    "# create loaders\n",
    "\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                            batch_size=4,\n",
    "                            shuffle=False, \n",
    "                            num_workers=NUM_WORKERS,\n",
    "                            pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2125b834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pose_body torch.Size([4, 10, 1, 189])\n",
      "root_orient torch.Size([4, 10, 1, 9])\n",
      "root_orient_vel torch.Size([4, 10, 1, 3])\n",
      "trans torch.Size([4, 10, 1, 3])\n",
      "trans_vel torch.Size([4, 10, 1, 3])\n",
      "joints torch.Size([4, 10, 1, 22, 3])\n",
      "joints_vel torch.Size([4, 10, 1, 22, 3])\n",
      "contacts torch.Size([4, 10, 1, 9])\n"
     ]
    }
   ],
   "source": [
    "for i, data in enumerate(train_loader):\n",
    "    data_in, data_out, meta = data\n",
    "    for k, v in data_in.items():\n",
    "        print(k, v.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3c9863b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "path=r'body_models\\smplh\\neutral\\model.npz'\n",
    "neutral_bm = BodyModel(bm_path=path, num_betas=16, batch_size=args.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e86137fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, data in enumerate(train_loader):\n",
    "    data_in, data_out, meta = data\n",
    "    pose = data_in['pose_body']\n",
    "    beta = meta['betas']\n",
    "    root_orient = data_in['root_orient']\n",
    "    trans = data_in['trans']\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f31be95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path= r\"E:\\workspace\\Motion\\AMASS\\amass_processed\\DanceDB\\20140805_NikosMichael\\Nikos_Zeibekiko_v2_C3D_poses_5170_frames_30_fps.npz\"\n",
    "\n",
    "data = np.load(path, allow_pickle=True)\n",
    "\n",
    "pose_body = data['pose_body'] # N x 63\n",
    "root_orient = data['root_orient'] # N x 3\n",
    "pose_hand = np.zeros((pose_body.shape[0], 6))\n",
    "\n",
    "pose = np.concatenate([root_orient, pose_body, pose_hand], axis=1) # N x 72\n",
    "trans = data['trans']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3cae0c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_dict = {\n",
    "    \"smpl_poses\": pose,\n",
    "    \"smpl_trans\": trans,\n",
    "    \"smpl_scaling\": np.ones((pose.shape[0], 1)),\n",
    "    \"smpl_betas\": np.zeros((pose.shape[0], 16)),\n",
    "}\n",
    "name = path.split('\\\\')[-1].split('.')[0]\n",
    "\n",
    "save_path = f\"out/vis/{name}.pkl\"\n",
    "\n",
    "with open(save_path, 'wb') as f:\n",
    "    pickle.dump(pkl_dict, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9e9d0f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_mask = np.zeros((pose.shape[0], 72))\n",
    "for i in range(pose.shape[1]):\n",
    "    if i in [42, 43, 44, 51, 52, 53, 57, 58, 59, 63, 64, 65]:\n",
    "        continue\n",
    "    pose_mask[:, i] = pose[:, i]\n",
    "    \n",
    "pkl_mask_dict = {\n",
    "    \"smpl_poses\": pose_mask,\n",
    "    \"smpl_trans\": trans,\n",
    "    \"smpl_scaling\": np.ones((pose.shape[0], 1)),\n",
    "    \"smpl_betas\": np.zeros((pose.shape[0], 16)),\n",
    "}\n",
    "\n",
    "save_path = f\"out/vis/{name}_mask.pkl\"\n",
    "with open(save_path, 'wb') as f:\n",
    "    pickle.dump(pkl_mask_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2ba888",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = np.random.randn(pose.shape[0], 72) * 0.8\n",
    "noise_dict = {\n",
    "    \"smpl_poses\": noise + pose,\n",
    "    \"smpl_trans\": trans,\n",
    "    \"smpl_scaling\": np.ones((pose.shape[0], 1)),\n",
    "    \"smpl_betas\": np.zeros((pose.shape[0], 16)),\n",
    "}\n",
    "save_path = f\"out/vis/{name}_noise.pkl\"\n",
    "with open(save_path, 'wb') as f:\n",
    "    pickle.dump(noise_dict, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CS280",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
