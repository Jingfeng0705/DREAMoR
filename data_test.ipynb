{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a772527",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from humor.datasets.amass_discrete_dataset import AmassDiscreteDataset\n",
    "from humor.datasets.amass_fit_dataset import AMASSFitDataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f02d6de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data roots:  ../datasets/AMASS/amass_processed\n"
     ]
    }
   ],
   "source": [
    "# configs\n",
    "data_path  = r\"../datasets/AMASS/amass_processed\"\n",
    "data_roots = data_path \n",
    "split_by = 'sequence'\n",
    "sample_num_frames = 10\n",
    "data_steps_in = 1\n",
    "data_steps_out = 1\n",
    "data_rot_rep = 'mat'\n",
    "data_return_config  = \"smpl+joints+contacts\"\n",
    "\n",
    "print(\"Data roots: \", data_roots)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97944e5",
   "metadata": {},
   "source": [
    "## Training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e7d7dbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from../datasets/AMASS/amass_processed\n",
      "Logger must be initialized before logging!\n",
      "This split contains 286 sequences (that meet the duration criteria).\n",
      "Logger must be initialized before logging!\n",
      "The dataset contains 18411 sub-sequences in total.\n",
      "Logger must be initialized before logging!\n"
     ]
    }
   ],
   "source": [
    "dataset = AmassDiscreteDataset(\n",
    "    split='train',\n",
    "    data_paths=data_roots,\n",
    "    split_by=split_by,\n",
    "    sample_num_frames=sample_num_frames,\n",
    "    step_frames_in=data_steps_in,\n",
    "    step_frames_out=data_steps_out,\n",
    "    data_rot_rep=data_rot_rep,\n",
    "    data_return_config=data_return_config,\n",
    ")\n",
    "loader = DataLoader(dataset, \n",
    "                        batch_size=1,\n",
    "                        shuffle=True,\n",
    "                        num_workers=0,\n",
    "                        pin_memory=True,\n",
    "                        drop_last=False,\n",
    "                        worker_init_fn=lambda _: np.random.seed()) # get around numpy RNG seed bug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "038ce6b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_in[pose_body]: torch.Size([1, 10, 1, 189])\n",
      "data_in[root_orient]: torch.Size([1, 10, 1, 9])\n",
      "data_in[root_orient_vel]: torch.Size([1, 10, 1, 3])\n",
      "data_in[trans]: torch.Size([1, 10, 1, 3])\n",
      "data_in[trans_vel]: torch.Size([1, 10, 1, 3])\n",
      "data_in[joints]: torch.Size([1, 10, 1, 22, 3])\n",
      "data_in[joints_vel]: torch.Size([1, 10, 1, 22, 3])\n",
      "data_in[contacts]: torch.Size([1, 10, 1, 9])\n"
     ]
    }
   ],
   "source": [
    "for i, (data_in, data_out, meta) in enumerate(loader):\n",
    "    for k, v in data_in.items():\n",
    "        print(f\"data_in[{k}]: {v.shape}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7362d6be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from../datasets/AMASS/amass_processed\n",
      "Logger must be initialized before logging!\n",
      "This split contains 66 sequences (that meet the duration criteria).\n",
      "Logger must be initialized before logging!\n",
      "The dataset contains 1281 sub-sequences in total.\n",
      "Logger must be initialized before logging!\n"
     ]
    }
   ],
   "source": [
    "fit_dataset = AMASSFitDataset(\n",
    "    data_path=data_roots,\n",
    "    seq_len=60,\n",
    "    return_joints=True,\n",
    "    return_verts=False,\n",
    "    return_points=False,\n",
    "    noise_std=0.04,\n",
    "    make_partial=False,\n",
    "    partial_height=0.9,\n",
    "    drop_middle=False,\n",
    "    root_only=False,\n",
    "    split_by='sequence',\n",
    "    custom_split=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6b1e76",
   "metadata": {},
   "source": [
    "## FitDataset with joints config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00443d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(fit_dataset, \n",
    "                            batch_size=1,\n",
    "                            shuffle=False,\n",
    "                            num_workers=0,\n",
    "                            pin_memory=True,\n",
    "                            drop_last=False,\n",
    "                            worker_init_fn=lambda _: np.random.seed())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "267f22f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observed_data keys: dict_keys(['joints3d'])\n",
      "gt_data keys: dict_keys(['root_orient', 'trans', 'joints', 'verts', 'trans_vel', 'root_orient_vel', 'joints_vel', 'pose_body', 'contacts', 'betas', 'gender', 'name'])\n",
      "observed_data['joints3d']: torch.Size([1, 60, 22, 3])\n",
      "gt_data[root_orient]: torch.Size([1, 60, 3])\n",
      "gt_data[trans]: torch.Size([1, 60, 3])\n",
      "gt_data[joints]: torch.Size([1, 60, 22, 3])\n",
      "gt_data[verts]: torch.Size([1, 60, 43, 3])\n",
      "gt_data[trans_vel]: torch.Size([1, 60, 3])\n",
      "gt_data[root_orient_vel]: torch.Size([1, 60, 3])\n",
      "gt_data[joints_vel]: torch.Size([1, 60, 22, 3])\n",
      "gt_data[pose_body]: torch.Size([1, 60, 63])\n",
      "gt_data[contacts]: torch.Size([1, 60, 22])\n",
      "gt_data[betas]: torch.Size([1, 60, 16])\n",
      "gt_data[gender]: ['female']\n",
      "gt_data[name]: ['datasets_AMASS_amass_processed\\\\ACCAD\\\\Female1General_c3d\\\\A7 - crouch_poses_121_frames_30_fps']\n"
     ]
    }
   ],
   "source": [
    "for i, data in enumerate(data_loader):\n",
    "    observed_data, gt_data = data\n",
    "    print(f\"observed_data keys: {observed_data.keys()}\")\n",
    "    print(f\"gt_data keys: {gt_data.keys()}\")\n",
    "    print(f\"observed_data['joints3d']: {observed_data['joints3d'].shape}\")\n",
    "    for k, v in gt_data.items():\n",
    "        if k != \"gender\" and k != \"name\":\n",
    "            print(f\"gt_data[{k}]: {v.shape}\")\n",
    "        else:\n",
    "            print(f\"gt_data[{k}]: {v}\")\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CS280",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
